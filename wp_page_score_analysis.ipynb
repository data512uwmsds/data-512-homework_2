{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Article Page Info MediaWiki API Example\n",
    "This example illustrates how to access page info data using the [MediaWiki REST API for the EN Wikipedia](https://www.mediawiki.org/wiki/API:Main_page). This example shows how to request summary 'page info' for a single article page. The API documentation, [API:Info](https://www.mediawiki.org/wiki/API:Info), covers additional details that may be helpful when trying to use or understand this example.\n",
    "\n",
    "## License\n",
    "This code example was developed by Dr. David W. McDonald for use in DATA 512, a course in the UW MS Data Science degree program. This code is provided under the [Creative Commons](https://creativecommons.org) [CC-BY license](https://creativecommons.org/licenses/by/4.0/). Revision 1.2 - September 16, 2024\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \n",
    "# These are standard python modules\n",
    "import json, time, urllib.parse\n",
    "#\n",
    "# The 'requests' module is not a standard Python module. You will need to install this with pip/pip3 if you do not already have it\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Define configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wiki configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "# The basic English Wikipedia API endpoint\n",
    "API_ENWIKIPEDIA_ENDPOINT = \"https://en.wikipedia.org/w/api.php\"\n",
    "API_HEADER_AGENT = 'User-Agent'\n",
    "\n",
    "# We'll assume that there needs to be some throttling for these requests - we should always be nice to a free data resource\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "\n",
    "# When making automated requests we should include something that is unique to the person making the request\n",
    "# This should include an email - your UW email would be good to put in there\n",
    "email_address = \"nguyenbh@uw.edu\"\n",
    "REQUEST_HEADERS = {\n",
    "    'User-Agent': f'<{email_address}>, University of Washington, MSDS DATA 512 - AUTUMN 2024'\n",
    "}\n",
    "\n",
    "# This is a string of additional page properties that can be returned see the Info documentation for\n",
    "# what can be included. If you don't want any this can simply be the empty string\n",
    "PAGEINFO_EXTENDED_PROPERTIES = \"talkid|url|watched|watchers\"\n",
    "#PAGEINFO_EXTENDED_PROPERTIES = \"\"\n",
    "\n",
    "# This template lists the basic parameters for making this\n",
    "PAGEINFO_PARAMS_TEMPLATE = {\n",
    "    \"action\": \"query\",\n",
    "    \"format\": \"json\",\n",
    "    \"titles\": \"\",           # to simplify this should be a single page title at a time\n",
    "    \"prop\": \"info\",\n",
    "    \"inprop\": PAGEINFO_EXTENDED_PROPERTIES\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ORES Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "#    The current LiftWing ORES API endpoint and prediction model\n",
    "#\n",
    "API_ORES_LIFTWING_ENDPOINT = \"https://api.wikimedia.org/service/lw/inference/v1/models/{model_name}:predict\"\n",
    "API_ORES_EN_QUALITY_MODEL = \"enwiki-articlequality\"\n",
    "\n",
    "#\n",
    "#    The throttling rate is a function of the Access token that you are granted when you request the token. The constants\n",
    "#    come from dissecting the token and getting the rate limits from the granted token. An example of that is below.\n",
    "#\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = ((60.0*60.0)/5000.0)-API_LATENCY_ASSUMED  # The key authorizes 5000 requests per hour\n",
    "\n",
    "#    When making automated requests we should include something that is unique to the person making the request\n",
    "#    This should include an email - your UW email would be good to put in there\n",
    "#    \n",
    "#    Because all LiftWing API requests require some form of authentication, you need to provide your access token\n",
    "#    as part of the header too\n",
    "#\n",
    "REQUEST_HEADER_TEMPLATE = {\n",
    "    'User-Agent': f\"<{email_address}>, University of Washington, MSDS DATA 512 - AUTUMN 2024\",\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': \"Bearer {access_token}\"\n",
    "}\n",
    "#\n",
    "#    This is a template for the parameters that we need to supply in the headers of an API request\n",
    "#\n",
    "REQUEST_HEADER_PARAMS_TEMPLATE = {\n",
    "    'email_address' : \"\",         # your email address should go here\n",
    "    'access_token'  : \"\"          # the access token you create will need to go here\n",
    "}\n",
    "\n",
    "#\n",
    "#    A dictionary of English Wikipedia article titles (keys) and sample revision IDs that can be used for this ORES scoring example\n",
    "#\n",
    "# ARTICLE_REVISIONS = { 'Bison':1085687913 , 'Northern flicker':1086582504 , 'Red squirrel':1083787665 , 'Chinook salmon':1085406228 , 'Horseshoe bat':1060601936 }\n",
    "\n",
    "#\n",
    "#    This is a template of the data required as a payload when making a scoring request of the ORES model\n",
    "#\n",
    "ORES_REQUEST_DATA_TEMPLATE = {\n",
    "    \"lang\":        \"en\",     # required that its english - we're scoring English Wikipedia revisions\n",
    "    \"rev_id\":      \"\",       # this request requires a revision id\n",
    "    \"features\":    True\n",
    "}\n",
    "\n",
    "#\n",
    "#    These are used later - defined here so they, at least, have empty values\n",
    "#\n",
    "USERNAME = \"\"\n",
    "ACCESS_TOKEN = \"\"\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wikipedia username & Access Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A key for the wikimedia API\n"
     ]
    }
   ],
   "source": [
    "from apikeys.KeyManager import KeyManager\n",
    "keyman = KeyManager()\n",
    "\n",
    "#\n",
    "#   This is my Wikipedia/Wikimedia username. They suggest you request your keys using your Wikipedia username, so I\n",
    "#   also stored the API key using my Wikipedia username.\n",
    "#\n",
    "#   You should probably use your own username here.\n",
    "USERNAME = \"nguyenbhuw\"\n",
    "key_info = keyman.findRecord(USERNAME)\n",
    "ACCESS_TOKEN = key_info[0]['access_token']\n",
    "print(key_info[0]['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define function to get page information for a given Wikipedia article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    PROCEDURES/FUNCTIONS\n",
    "#\n",
    "\n",
    "\n",
    "def request_pageinfo_per_article(article_title = None, \n",
    "                                 endpoint_url = API_ENWIKIPEDIA_ENDPOINT, \n",
    "                                 request_template = PAGEINFO_PARAMS_TEMPLATE,\n",
    "                                 headers = REQUEST_HEADERS):\n",
    "    \"\"\"\n",
    "    Requests page information for a given Wikipedia article.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    article_title : str, optional\n",
    "        The title of the Wikipedia article to request information for. If not provided, \n",
    "        the title must be included in the request_template.\n",
    "    endpoint_url : str, optional\n",
    "        The URL endpoint for the Wikipedia API. Defaults to API_ENWIKIPEDIA_ENDPOINT.\n",
    "    request_template : dict, optional\n",
    "        The template dictionary containing request parameters. Defaults to PAGEINFO_PARAMS_TEMPLATE.\n",
    "    headers : dict, optional\n",
    "        The headers to include in the request. Defaults to REQUEST_HEADERS.\n",
    "    Returns:\n",
    "    --------\n",
    "    dict or None\n",
    "        The JSON response from the Wikipedia API if the request is successful, otherwise None.\n",
    "    Raises:\n",
    "    -------\n",
    "    Exception\n",
    "        If no article title is provided or included in the request_template.\n",
    "        If the headers do not include the required API_HEADER_AGENT field.\n",
    "        If the API_HEADER_AGENT field does not contain a valid UW email address.\n",
    "    \"\"\"\n",
    "    \n",
    "    # article title can be as a parameter to the call or in the request_template\n",
    "    if article_title:\n",
    "        request_template['titles'] = article_title\n",
    "\n",
    "    if not request_template['titles']:\n",
    "        raise Exception(\"Must supply an article title to make a pageinfo request.\")\n",
    "\n",
    "    if API_HEADER_AGENT not in headers:\n",
    "        raise Exception(f\"The header data should include a '{API_HEADER_AGENT}' field that contains your UW email address.\")\n",
    "\n",
    "    if 'uwnetid@uw' in headers[API_HEADER_AGENT]:\n",
    "        raise Exception(f\"Use your UW email address in the '{API_HEADER_AGENT}' field.\")\n",
    "\n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free\n",
    "        # data source like Wikipedia - or any other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(endpoint_url, headers=headers, params=request_template)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define a function to make the ORES API request\n",
    "\n",
    "The API request will be made using a function to encapsulate call and make access reusable in other notebooks. The procedure is parameterized, relying on the constants above for some important default parameters. The primary assumption is that this function will be used to request data for a set of article revisions. The main parameter is 'article_revid'. One should be able to simply pass in a new article revision id on each call and get back a python dictionary as the result. A valid result will be a dictionary that contains the probabilities that the specific revision is one of six different article quality levels. Generally, quality level with the highest probability score is considered the quality level for the article. This can be tricky when you have two (or more) highly probable quality levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    PROCEDURES/FUNCTIONS\n",
    "#\n",
    "\n",
    "def request_ores_score_per_article(article_revid = None, email_address=None, access_token=None,\n",
    "                                   endpoint_url = API_ORES_LIFTWING_ENDPOINT, \n",
    "                                   model_name = API_ORES_EN_QUALITY_MODEL, \n",
    "                                   request_data = ORES_REQUEST_DATA_TEMPLATE, \n",
    "                                   header_format = REQUEST_HEADER_TEMPLATE, \n",
    "                                   header_params = REQUEST_HEADER_PARAMS_TEMPLATE):\n",
    "    \n",
    "    \"\"\"\n",
    "    Requests an ORES score for a given article revision ID.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    article_revid : int, optional\n",
    "        The revision ID of the article to be scored. Default is None.\n",
    "    email_address : str, optional\n",
    "        The email address to be included in the request header. Default is None.\n",
    "    access_token : str, optional\n",
    "        The access token to be included in the request header. Default is None.\n",
    "    endpoint_url : str, optional\n",
    "        The endpoint URL for the ORES API. Default is API_ORES_LIFTWING_ENDPOINT.\n",
    "    model_name : str, optional\n",
    "        The model name to be used for scoring. Default is API_ORES_EN_QUALITY_MODEL.\n",
    "    request_data : dict, optional\n",
    "        The template for the request data. Default is ORES_REQUEST_DATA_TEMPLATE.\n",
    "    header_format : dict, optional\n",
    "        The template for the request header format. Default is REQUEST_HEADER_TEMPLATE.\n",
    "    header_params : dict, optional\n",
    "        The template for the request header parameters. Default is REQUEST_HEADER_PARAMS_TEMPLATE.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict or None\n",
    "        The JSON response from the ORES API if the request is successful, otherwise None.\n",
    "   \n",
    "    Raises:\n",
    "    -------\n",
    "    Exception\n",
    "        Throw exception if the required parameters \n",
    "        (article_revid, email_address, access_token) are not provided.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    #    Make sure we have an article revision id, email and token\n",
    "    #    This approach prioritizes the parameters passed in when making the call\n",
    "    if article_revid:\n",
    "        request_data['rev_id'] = article_revid\n",
    "    if email_address:\n",
    "        header_params['email_address'] = email_address\n",
    "    if access_token:\n",
    "        header_params['access_token'] = access_token\n",
    "    \n",
    "    #   Making a request requires a revision id - an email address - and the access token\n",
    "    if not request_data['rev_id']:\n",
    "        raise Exception(\"Must provide an article revision id (rev_id) to score articles\")\n",
    "    if not header_params['email_address']:\n",
    "        raise Exception(\"Must provide an 'email_address' value\")\n",
    "    if not header_params['access_token']:\n",
    "        raise Exception(\"Must provide an 'access_token' value\")\n",
    "    \n",
    "    # Create the request URL with the specified model parameter - default is a article quality score request\n",
    "    request_url = endpoint_url.format(model_name=model_name)\n",
    "    \n",
    "    # Create a compliant request header from the template and the supplied parameters\n",
    "    headers = dict()\n",
    "    for key in header_format.keys():\n",
    "        headers[str(key)] = header_format[key].format(**header_params)\n",
    "    \n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free data\n",
    "        # source like ORES - or other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        #response = requests.get(request_url, headers=headers)\n",
    "        response = requests.post(request_url, headers=headers, data=json.dumps(request_data))\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data\n",
    "\n",
    "Read in politician & population data. The population data contains both regions' names & countries' names. The data is in hierarchy. Based on this hierarchy, create another column called `region` & fill in the region for each country (use the lowest region in the hierarchy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         name                                                       url      country\n",
      "0              Majah Ha Adrif              https://en.wikipedia.org/wiki/Majah_Ha_Adrif  Afghanistan\n",
      "1           Haroon al-Afghani           https://en.wikipedia.org/wiki/Haroon_al-Afghani  Afghanistan\n",
      "2                 Tayyab Agha                 https://en.wikipedia.org/wiki/Tayyab_Agha  Afghanistan\n",
      "3        Khadija Zahra Ahmadi        https://en.wikipedia.org/wiki/Khadija_Zahra_Ahmadi  Afghanistan\n",
      "4              Aziza Ahmadyar              https://en.wikipedia.org/wiki/Aziza_Ahmadyar  Afghanistan\n",
      "5           Muqadasa Ahmadzai           https://en.wikipedia.org/wiki/Muqadasa_Ahmadzai  Afghanistan\n",
      "6    Mohammad Sarwar Ahmedzai    https://en.wikipedia.org/wiki/Mohammad_Sarwar_Ahmedzai  Afghanistan\n",
      "7    Amir Muhammad Akhundzada    https://en.wikipedia.org/wiki/Amir_Muhammad_Akhundzada  Afghanistan\n",
      "8  Nasrullah Baryalai Arsalai  https://en.wikipedia.org/wiki/Nasrullah_Baryalai_Arsalai  Afghanistan\n",
      "9          Abdul Rahim Ayoubi          https://en.wikipedia.org/wiki/Abdul_Rahim_Ayoubi  Afghanistan\n",
      "         geography  population           region\n",
      "0            WORLD      8009.0            WORLD\n",
      "1           AFRICA      1453.0           AFRICA\n",
      "2  NORTHERN AFRICA       256.0  NORTHERN AFRICA\n",
      "3          Algeria        46.8  NORTHERN AFRICA\n",
      "4            Egypt       105.2  NORTHERN AFRICA\n",
      "5            Libya         6.9  NORTHERN AFRICA\n",
      "6          Morocco        37.0  NORTHERN AFRICA\n",
      "7            Sudan        48.1  NORTHERN AFRICA\n",
      "8          Tunisia        11.9  NORTHERN AFRICA\n",
      "9   Western Sahara         0.6  NORTHERN AFRICA\n",
      "            geography  population   region\n",
      "223             Nauru         0.0  OCEANIA\n",
      "224     New Caledonia         0.3  OCEANIA\n",
      "225       New Zealand         5.2  OCEANIA\n",
      "226             Palau         0.0  OCEANIA\n",
      "227  Papua New Guinea         9.5  OCEANIA\n",
      "228             Samoa         0.2  OCEANIA\n",
      "229   Solomon Islands         0.8  OCEANIA\n",
      "230             Tonga         0.1  OCEANIA\n",
      "231            Tuvalu         0.0  OCEANIA\n",
      "232           Vanuatu         0.3  OCEANIA\n"
     ]
    }
   ],
   "source": [
    "politicians_data_path = 'raw/politicians_by_country_AUG.2024.csv'\n",
    "populations_data_path = 'raw/population_by_country_AUG.2024.csv'\n",
    "output_path = 'data/wp_politicians_by_country.csv' # Output file path\n",
    "error_path = 'data/wp_errors.txt' # Error log file path\n",
    "\n",
    "politician_df = pd.read_csv(politicians_data_path)\n",
    "population_df = pd.read_csv(populations_data_path)\n",
    "population_df.columns = population_df.columns.str.lower()\n",
    "\n",
    "# Process the population data\n",
    "population_df['region'] = population_df['geography'].where(population_df['geography'].str.isupper())\n",
    "# Forward-fill the region values down the DataFrame\n",
    "population_df['region'] = population_df['region'].ffill()\n",
    "\n",
    "# Filter out rows where the Geography column is a region (i.e., in all uppercase)\n",
    "country_df = population_df[population_df['geography'].str.islower() | population_df['geography'].str.istitle()]\n",
    "country_df\n",
    "\n",
    "print(politician_df.head(10).to_string())\n",
    "print(population_df.head(10).to_string())\n",
    "print(country_df.tail(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Combining the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the dataset to see which countries appear in one csv file but not the other. Save non-matching countries to a txt file.\n",
    "\n",
    "For matching countries, join the politician & population data together by country name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-matching countries: 48\n"
     ]
    }
   ],
   "source": [
    "# Find the non-matching countries\n",
    "popul_countries = set(country_df['geography'])\n",
    "poli_countries = set(politician_df['country'])\n",
    "difference = (popul_countries - poli_countries).union(poli_countries - popul_countries)\n",
    "# Savt to txt file\n",
    "no_match_path = 'data/wp_countries-no_match.txt'\n",
    "with open(no_match_path, 'w') as f:\n",
    "    for item in difference:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "print(f\"Number of non-matching countries: {len(difference)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>url</th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Majah Ha Adrif</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Majah_Ha_Adrif</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haroon al-Afghani</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Haroon_al-Afghani</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tayyab Agha</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Tayyab_Agha</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Khadija Zahra Ahmadi</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Khadija_Zahra_Ah...</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aziza Ahmadyar</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Aziza_Ahmadyar</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6873</th>\n",
       "      <td>Josiah Tongogara</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Josiah_Tongogara</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>16.7</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6874</th>\n",
       "      <td>Langton Towungana</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Langton_Towungana</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>16.7</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6875</th>\n",
       "      <td>Sengezo Tshabangu</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Sengezo_Tshabangu</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>16.7</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6876</th>\n",
       "      <td>Herbert Ushewokunze</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Herbert_Ushewokunze</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>16.7</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6877</th>\n",
       "      <td>Denis Walker</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Denis_Walker</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>16.7</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6878 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             article_title                                                url  \\\n",
       "0           Majah Ha Adrif       https://en.wikipedia.org/wiki/Majah_Ha_Adrif   \n",
       "1        Haroon al-Afghani    https://en.wikipedia.org/wiki/Haroon_al-Afghani   \n",
       "2              Tayyab Agha          https://en.wikipedia.org/wiki/Tayyab_Agha   \n",
       "3     Khadija Zahra Ahmadi  https://en.wikipedia.org/wiki/Khadija_Zahra_Ah...   \n",
       "4           Aziza Ahmadyar       https://en.wikipedia.org/wiki/Aziza_Ahmadyar   \n",
       "...                    ...                                                ...   \n",
       "6873      Josiah Tongogara     https://en.wikipedia.org/wiki/Josiah_Tongogara   \n",
       "6874     Langton Towungana    https://en.wikipedia.org/wiki/Langton_Towungana   \n",
       "6875     Sengezo Tshabangu    https://en.wikipedia.org/wiki/Sengezo_Tshabangu   \n",
       "6876   Herbert Ushewokunze  https://en.wikipedia.org/wiki/Herbert_Ushewokunze   \n",
       "6877          Denis Walker         https://en.wikipedia.org/wiki/Denis_Walker   \n",
       "\n",
       "          country  population          region  \n",
       "0     Afghanistan        42.4      SOUTH ASIA  \n",
       "1     Afghanistan        42.4      SOUTH ASIA  \n",
       "2     Afghanistan        42.4      SOUTH ASIA  \n",
       "3     Afghanistan        42.4      SOUTH ASIA  \n",
       "4     Afghanistan        42.4      SOUTH ASIA  \n",
       "...           ...         ...             ...  \n",
       "6873     Zimbabwe        16.7  EASTERN AFRICA  \n",
       "6874     Zimbabwe        16.7  EASTERN AFRICA  \n",
       "6875     Zimbabwe        16.7  EASTERN AFRICA  \n",
       "6876     Zimbabwe        16.7  EASTERN AFRICA  \n",
       "6877     Zimbabwe        16.7  EASTERN AFRICA  \n",
       "\n",
       "[6878 rows x 5 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the dataframes on the country and geography columns\n",
    "merged_df = pd.merge(politician_df, country_df, left_on='country', right_on='geography', how='inner')\n",
    "# delete the 'Geography' column\n",
    "merged_df.drop(columns=['geography'], inplace=True)\n",
    "# Rename the 'name' column to 'article_title'\n",
    "merged_df.rename(columns={'name': 'article_title'}, inplace=True)\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through all politicians in the policitican data that have matching countries in the population data. For each politician, make a request to the Wikipedia API to get the info and the **revision id**. Use this revision id to make a request to the ORES API to get the **score of the article quality**. Save these two fields to the combined dataset in step 3, and save it as a CSV file.\n",
    "During this proccess, record errors into a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total errors: 9. Error rate: 0.13%\n",
      "Number of articles with no revision ID: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>url</th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>region</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>article_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Majah Ha Adrif</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Majah_Ha_Adrif</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>10483286</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haroon al-Afghani</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Haroon_al-Afghani</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>11966231</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tayyab Agha</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Tayyab_Agha</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>46841383</td>\n",
       "      <td>Stub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Khadija Zahra Ahmadi</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Khadija_Zahra_Ah...</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>71600382</td>\n",
       "      <td>Stub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aziza Ahmadyar</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Aziza_Ahmadyar</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>47805901</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6873</th>\n",
       "      <td>Josiah Tongogara</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Josiah_Tongogara</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>16.7</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>633594</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6874</th>\n",
       "      <td>Langton Towungana</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Langton_Towungana</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>16.7</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>16375315</td>\n",
       "      <td>Stub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6875</th>\n",
       "      <td>Sengezo Tshabangu</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Sengezo_Tshabangu</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>16.7</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>75270547</td>\n",
       "      <td>Stub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6876</th>\n",
       "      <td>Herbert Ushewokunze</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Herbert_Ushewokunze</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>16.7</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>11742819</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6877</th>\n",
       "      <td>Denis Walker</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Denis_Walker</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>16.7</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>3255571</td>\n",
       "      <td>Stub</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6878 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             article_title                                                url  \\\n",
       "0           Majah Ha Adrif       https://en.wikipedia.org/wiki/Majah_Ha_Adrif   \n",
       "1        Haroon al-Afghani    https://en.wikipedia.org/wiki/Haroon_al-Afghani   \n",
       "2              Tayyab Agha          https://en.wikipedia.org/wiki/Tayyab_Agha   \n",
       "3     Khadija Zahra Ahmadi  https://en.wikipedia.org/wiki/Khadija_Zahra_Ah...   \n",
       "4           Aziza Ahmadyar       https://en.wikipedia.org/wiki/Aziza_Ahmadyar   \n",
       "...                    ...                                                ...   \n",
       "6873      Josiah Tongogara     https://en.wikipedia.org/wiki/Josiah_Tongogara   \n",
       "6874     Langton Towungana    https://en.wikipedia.org/wiki/Langton_Towungana   \n",
       "6875     Sengezo Tshabangu    https://en.wikipedia.org/wiki/Sengezo_Tshabangu   \n",
       "6876   Herbert Ushewokunze  https://en.wikipedia.org/wiki/Herbert_Ushewokunze   \n",
       "6877          Denis Walker         https://en.wikipedia.org/wiki/Denis_Walker   \n",
       "\n",
       "          country  population          region  revision_id article_quality  \n",
       "0     Afghanistan        42.4      SOUTH ASIA     10483286           Start  \n",
       "1     Afghanistan        42.4      SOUTH ASIA     11966231               B  \n",
       "2     Afghanistan        42.4      SOUTH ASIA     46841383            Stub  \n",
       "3     Afghanistan        42.4      SOUTH ASIA     71600382            Stub  \n",
       "4     Afghanistan        42.4      SOUTH ASIA     47805901               B  \n",
       "...           ...         ...             ...          ...             ...  \n",
       "6873     Zimbabwe        16.7  EASTERN AFRICA       633594           Start  \n",
       "6874     Zimbabwe        16.7  EASTERN AFRICA     16375315            Stub  \n",
       "6875     Zimbabwe        16.7  EASTERN AFRICA     75270547            Stub  \n",
       "6876     Zimbabwe        16.7  EASTERN AFRICA     11742819               B  \n",
       "6877     Zimbabwe        16.7  EASTERN AFRICA      3255571            Stub  \n",
       "\n",
       "[6878 rows x 7 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = []\n",
    "scores = []\n",
    "revision_ids = []\n",
    "\n",
    "for i, row in merged_df.iterrows():\n",
    "    print(i)\n",
    "    article = row['article_title']\n",
    "    try:\n",
    "        info = request_pageinfo_per_article(article)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        errors.append((i,e))\n",
    "        scores.append(None)\n",
    "        revision_ids.append(None)\n",
    "        # raise Exception(e)\n",
    "        continue\n",
    "    try:\n",
    "        info_json = json.dumps(info['query']['pages'],indent=4)\n",
    "        revid = int(list(info['query']['pages'].keys())[0])\n",
    "        talk_id = int(list(info['query']['pages'].values())[0]['talkid'])\n",
    "        revision_ids.append(revid)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        errors.append((i,e))\n",
    "        scores.append(None)\n",
    "        revision_ids.append(None)\n",
    "        continue\n",
    "    try:\n",
    "        score_info = request_ores_score_per_article(article_revid=revid,\n",
    "                                       email_address=email_address,\n",
    "                                       access_token=ACCESS_TOKEN)\n",
    "        if 'error' in score_info:\n",
    "            try:\n",
    "                # Retry with revid ID with talk page ID\n",
    "                score_info = request_ores_score_per_article(article_revid=talk_id,\n",
    "                                       email_address=email_address,\n",
    "                                       access_token=ACCESS_TOKEN)\n",
    "            except Exception as e:\n",
    "                print(score_info['error'])\n",
    "                errors.append((i,score_info['error']))\n",
    "                score = None\n",
    "        else:\n",
    "            score =  list(score_info['enwiki']['scores'].values())[0]['articlequality']['score']['prediction']\n",
    "        scores.append(score)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        errors.append(i)\n",
    "        scores.append(None)\n",
    "    \n",
    "merged_df['revision_id'] = revision_ids\n",
    "merged_df['article_quality'] = scores\n",
    "\n",
    "if len(errors) > 0:\n",
    "    error_df = merged_df[merged_df['article_quality'].isna()]\n",
    "    print(f\"Total errors: {len(error_df.index)}. Error rate: {len(error_df.index)/len(merged_df)*100:.2f}%\")\n",
    "non_revid_idx = [x for x in revision_ids if x<0]\n",
    "print(f\"Number of articles with no revision ID: {len(non_revid_idx)}\")\n",
    "\n",
    "# Save the data to a CSV file\n",
    "merged_df.drop(columns=['url'], inplace=False).to_csv(output_path, index=False) # drop url column\n",
    "\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>url</th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>region</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>article_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Barbara Eibinger-Miedl</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Barbara_Eibinger...</td>\n",
       "      <td>Austria</td>\n",
       "      <td>9.2</td>\n",
       "      <td>WESTERN EUROPE</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>Mehrali Gasimov</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Mehrali_Gasimov</td>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>10.2</td>\n",
       "      <td>WESTERN ASIA</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>Kyaw Myint</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Kyaw_Myint</td>\n",
       "      <td>Myanmar</td>\n",
       "      <td>55.4</td>\n",
       "      <td>SOUTHEAST ASIA</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>André Ngongang Ouandji</td>\n",
       "      <td>https://en.wikipedia.org/wiki/André_Ngongang_O...</td>\n",
       "      <td>Cameroon</td>\n",
       "      <td>28.1</td>\n",
       "      <td>MIDDLE AFRICA</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>Tomás Pimentel</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Tomás_Pimentel</td>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>11.3</td>\n",
       "      <td>CARIBBEAN</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>Richard Sumah</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Richard_Sumah</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>34.1</td>\n",
       "      <td>WESTERN AFRICA</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3503</th>\n",
       "      <td>Adem Hodža</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Adem_Hodža</td>\n",
       "      <td>Kosovo</td>\n",
       "      <td>1.7</td>\n",
       "      <td>SOUTHERN EUROPE</td>\n",
       "      <td>65356695</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4322</th>\n",
       "      <td>Segun ''Aeroland'' Adewale</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Segun_''Aeroland...</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>223.8</td>\n",
       "      <td>WESTERN AFRICA</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5538</th>\n",
       "      <td>Bashir Bililiqo</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bashir_Bililiqo</td>\n",
       "      <td>Somalia</td>\n",
       "      <td>18.1</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   article_title  \\\n",
       "397       Barbara Eibinger-Miedl   \n",
       "483              Mehrali Gasimov   \n",
       "1159                  Kyaw Myint   \n",
       "1301      André Ngongang Ouandji   \n",
       "1861              Tomás Pimentel   \n",
       "2333               Richard Sumah   \n",
       "3503                  Adem Hodža   \n",
       "4322  Segun ''Aeroland'' Adewale   \n",
       "5538             Bashir Bililiqo   \n",
       "\n",
       "                                                    url             country  \\\n",
       "397   https://en.wikipedia.org/wiki/Barbara_Eibinger...             Austria   \n",
       "483       https://en.wikipedia.org/wiki/Mehrali_Gasimov          Azerbaijan   \n",
       "1159           https://en.wikipedia.org/wiki/Kyaw_Myint             Myanmar   \n",
       "1301  https://en.wikipedia.org/wiki/André_Ngongang_O...            Cameroon   \n",
       "1861       https://en.wikipedia.org/wiki/Tomás_Pimentel  Dominican Republic   \n",
       "2333        https://en.wikipedia.org/wiki/Richard_Sumah               Ghana   \n",
       "3503           https://en.wikipedia.org/wiki/Adem_Hodža              Kosovo   \n",
       "4322  https://en.wikipedia.org/wiki/Segun_''Aeroland...             Nigeria   \n",
       "5538      https://en.wikipedia.org/wiki/Bashir_Bililiqo             Somalia   \n",
       "\n",
       "      population           region  revision_id article_quality  \n",
       "397          9.2   WESTERN EUROPE           -1            None  \n",
       "483         10.2     WESTERN ASIA           -1            None  \n",
       "1159        55.4   SOUTHEAST ASIA           -1            None  \n",
       "1301        28.1    MIDDLE AFRICA           -1            None  \n",
       "1861        11.3        CARIBBEAN           -1            None  \n",
       "2333        34.1   WESTERN AFRICA           -1            None  \n",
       "3503         1.7  SOUTHERN EUROPE     65356695            None  \n",
       "4322       223.8   WESTERN AFRICA           -1            None  \n",
       "5538        18.1   EASTERN AFRICA           -1            None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(397,\n",
       "  'The MW API does not have any info related to the rev-id provided as input (-1), therefore it is not possible to extract features properly. One possible cause is the deletion of the page related to the revision id. Please contact the ML-Team if you need more info.'),\n",
       " (483,\n",
       "  'The MW API does not have any info related to the rev-id provided as input (-1), therefore it is not possible to extract features properly. One possible cause is the deletion of the page related to the revision id. Please contact the ML-Team if you need more info.'),\n",
       " (1159,\n",
       "  'The MW API does not have any info related to the rev-id provided as input (-1), therefore it is not possible to extract features properly. One possible cause is the deletion of the page related to the revision id. Please contact the ML-Team if you need more info.'),\n",
       " (1301,\n",
       "  'The MW API does not have any info related to the rev-id provided as input (-1), therefore it is not possible to extract features properly. One possible cause is the deletion of the page related to the revision id. Please contact the ML-Team if you need more info.'),\n",
       " (1861,\n",
       "  'The MW API does not have any info related to the rev-id provided as input (-1), therefore it is not possible to extract features properly. One possible cause is the deletion of the page related to the revision id. Please contact the ML-Team if you need more info.'),\n",
       " (2333,\n",
       "  'The MW API does not have any info related to the rev-id provided as input (-1), therefore it is not possible to extract features properly. One possible cause is the deletion of the page related to the revision id. Please contact the ML-Team if you need more info.'),\n",
       " (3503,\n",
       "  'The MW API does not have any info related to the rev-id provided as input (65356695), therefore it is not possible to extract features properly. One possible cause is the deletion of the page related to the revision id. Please contact the ML-Team if you need more info.'),\n",
       " (4322,\n",
       "  'The MW API does not have any info related to the rev-id provided as input (-1), therefore it is not possible to extract features properly. One possible cause is the deletion of the page related to the revision id. Please contact the ML-Team if you need more info.'),\n",
       " (5538,\n",
       "  'The MW API does not have any info related to the rev-id provided as input (-1), therefore it is not possible to extract features properly. One possible cause is the deletion of the page related to the revision id. Please contact the ML-Team if you need more info.')]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the rows with errors\n",
    "error_df = merged_df[merged_df['article_quality'].isna()]\n",
    "display(error_df)\n",
    "\n",
    "# Get the revision_id column\n",
    "revision_ids = merged_df['revision_id'].tolist()\n",
    "article_titles = merged_df['article_title'].tolist()\n",
    "\n",
    "# Add revision_id & article titles to the errors list\n",
    "errors_updates = [(i, revision_ids[i], article_titles[i], e) for i, e in errors]\n",
    "\n",
    "# Save errors to a txt file\n",
    "with open(error_path, 'w') as f:\n",
    "    for error in errors_updates:\n",
    "        f.write(f\"Index: {error[0]}, Revision ID: {error[1]}, Article Title: {error[2]}, Error: {error[3]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Analysis\n",
    "\n",
    "The analysis consists of 2 calculations:\n",
    "1. Total articles per capita\n",
    "2. High quality articles per capita   \n",
    "    - Consider \"high quality\" articles to be articles that ORES predicted would be in either the \"FA\" (featured article) or \"GA\" (good article) classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "Afghanistan    2.004717e-06\n",
       "Albania        2.592593e-05\n",
       "Algeria        1.517094e-06\n",
       "Angola         1.580381e-06\n",
       "Argentina      1.382289e-06\n",
       "                   ...     \n",
       "Venezuela      1.944444e-06\n",
       "Vietnam        3.640040e-07\n",
       "Yemen          9.302326e-07\n",
       "Zambia         1.485149e-07\n",
       "Zimbabwe       4.131737e-06\n",
       "Length: 159, dtype: float64"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_count_by_country = merged_df.groupby('country')['article_title'].count()\n",
    "article_count_by_country = article_count_by_country.astype(float)\n",
    "\n",
    "# Filter out rows where the population is 0\n",
    "population_by_country = merged_df.groupby('country')['population'].first()*10**6\n",
    "population_by_country = population_by_country[population_by_country > 0]\n",
    "\n",
    "article_per_capita = article_count_by_country / population_by_country\n",
    "article_per_capita = article_per_capita.fillna(0)\n",
    "\n",
    "article_per_capita.to_csv('data/wp_article_per_capita.csv', header=True)\n",
    "article_per_capita\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "Afghanistan    9.433962e-08\n",
       "Albania        1.111111e-06\n",
       "Algeria        6.410256e-08\n",
       "Angola         5.449591e-08\n",
       "Argentina      4.319654e-08\n",
       "                   ...     \n",
       "Venezuela      3.472222e-08\n",
       "Vietnam        4.044489e-08\n",
       "Yemen          8.720930e-08\n",
       "Zambia         0.000000e+00\n",
       "Zimbabwe       0.000000e+00\n",
       "Length: 159, dtype: float64"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_qualities = ['FA', 'GA']\n",
    "hi_quality_articles = merged_df.loc[merged_df['article_quality'].isin(high_qualities)]\n",
    "hi_article_count_by_country = hi_quality_articles.groupby('country')['article_title'].count()\n",
    "hi_article_count_by_country = hi_article_count_by_country.astype(float)\n",
    "\n",
    "hi_article_per_capita = hi_article_count_by_country / population_by_country\n",
    "hi_article_per_capita = hi_article_per_capita.fillna(0)\n",
    "\n",
    "hi_article_per_capita.to_csv('data/wp_high_quality_article_per_capita.csv', header=True)\n",
    "hi_article_per_capita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Results\n",
    "\n",
    "This result section shows 6 tables to summarize the data.\n",
    "1. Top 10 countries by coverage: The 10 countries with the highest total articles per capita (in descending order) .\n",
    "2. Bottom 10 countries by coverage: The 10 countries with the lowest total articles per capita (in ascending order) .\n",
    "3. Top 10 countries by high quality: The 10 countries with the highest high quality articles per capita (in descending order) .\n",
    "4. Bottom 10 countries by high quality: The 10 countries with the lowest high quality articles per capita (in ascending order).\n",
    "5. Geographic regions by total coverage: A rank ordered list of geographic regions (in descending order) by total articles per capita.\n",
    "6. Geographic regions by high quality coverage: Rank ordered list of geographic regions (in descending order) by high quality articles per capita.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 1: Top 10 countries by coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "Marshall Islands    0.000130\n",
       "Tonga               0.000100\n",
       "Barbados            0.000083\n",
       "Montenegro          0.000060\n",
       "Seychelles          0.000060\n",
       "Bhutan              0.000055\n",
       "Maldives            0.000055\n",
       "Samoa               0.000040\n",
       "Luxembourg          0.000039\n",
       "Bahrain             0.000027\n",
       "dtype: float64"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the top 10 countries by articles per capita\n",
    "top_10_countries_by_coverage = article_per_capita.sort_values(ascending=False).head(10)\n",
    "top_10_countries_by_coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 2: Bottom 10 countries by coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "Monaco          0.000000e+00\n",
       "Tuvalu          0.000000e+00\n",
       "China           1.133707e-08\n",
       "India           1.056979e-07\n",
       "Ghana           1.173021e-07\n",
       "Saudi Arabia    1.355014e-07\n",
       "Zambia          1.485149e-07\n",
       "Norway          1.818182e-07\n",
       "Israel          2.040816e-07\n",
       "Egypt           3.041825e-07\n",
       "dtype: float64"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_10_countries_by_coverage = article_per_capita.sort_values(ascending=True).head(10)\n",
    "bot_10_countries_by_coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 3: Top 10 countries by high quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "Seychelles               1.000000e-05\n",
       "Barbados                 3.333333e-06\n",
       "Luxembourg               2.857143e-06\n",
       "Maldives                 1.666667e-06\n",
       "Guyana                   1.250000e-06\n",
       "Albania                  1.111111e-06\n",
       "Comoros                  1.111111e-06\n",
       "Moldova                  8.823529e-07\n",
       "Palestinian Territory    7.272727e-07\n",
       "Bahrain                  6.250000e-07\n",
       "dtype: float64"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_countries_by_hi_qual = hi_article_per_capita.sort_values(ascending=False).head(10)\n",
    "top_10_countries_by_hi_qual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 4: Bottom 10 countries by high quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "Armenia                     0.0\n",
       "Belgium                     0.0\n",
       "Belize                      0.0\n",
       "Benin                       0.0\n",
       "Belarus                     0.0\n",
       "Bahamas                     0.0\n",
       "Botswana                    0.0\n",
       "Bhutan                      0.0\n",
       "Central African Republic    0.0\n",
       "Cape Verde                  0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_10_countries_by_hi_qual = hi_article_per_capita.sort_values(ascending=True).head(10)\n",
    "bot_10_countries_by_hi_qual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 5: Geographic regions by total coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region\n",
       "OCEANIA            5.287147e-07\n",
       "NORTHERN EUROPE    1.643576e-07\n",
       "CENTRAL AMERICA    1.325063e-07\n",
       "CARIBBEAN          1.161868e-07\n",
       "CENTRAL ASIA       5.343819e-08\n",
       "WESTERN ASIA       4.562624e-08\n",
       "SOUTHERN EUROPE    4.438479e-08\n",
       "MIDDLE AFRICA      4.338289e-08\n",
       "EASTERN AFRICA     2.777639e-08\n",
       "WESTERN EUROPE     2.625212e-08\n",
       "NORTHERN AFRICA    2.480717e-08\n",
       "EASTERN EUROPE     2.441048e-08\n",
       "SOUTHERN AFRICA    2.065734e-08\n",
       "SOUTH AMERICA      1.648602e-08\n",
       "SOUTHEAST ASIA     8.794450e-09\n",
       "WESTERN AFRICA     8.607011e-09\n",
       "EAST ASIA          4.062781e-09\n",
       "SOUTH ASIA         2.536326e-09\n",
       "dtype: float64"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a rank ordered list of geographic regions (in descending order) by total articles per capita.\n",
    "\n",
    "# Group by region and sum the articles and population\n",
    "region_article_counts = merged_df.groupby('region')['article_title'].count()\n",
    "region_population_sums = merged_df.groupby('region')['population'].sum()\n",
    "\n",
    "# Calculate articles per capita for each region\n",
    "region_articles_per_capita = region_article_counts / (region_population_sums * 10**6)\n",
    "\n",
    "region_articles_per_capita_sorted = region_articles_per_capita.sort_values(ascending=False)\n",
    "region_articles_per_capita_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 6: Geographic regions by high quality coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region\n",
       "CARIBBEAN          1.310044e-07\n",
       "SOUTHERN EUROPE    1.094092e-07\n",
       "CENTRAL AMERICA    1.057082e-07\n",
       "NORTHERN EUROPE    9.523810e-08\n",
       "WESTERN ASIA       4.212860e-08\n",
       "MIDDLE AFRICA      2.955665e-08\n",
       "EASTERN AFRICA     2.636667e-08\n",
       "NORTHERN AFRICA    2.604920e-08\n",
       "WESTERN EUROPE     2.580275e-08\n",
       "SOUTH AMERICA      2.572220e-08\n",
       "EASTERN EUROPE     1.956309e-08\n",
       "SOUTHERN AFRICA    1.647446e-08\n",
       "SOUTHEAST ASIA     1.250120e-08\n",
       "EAST ASIA          1.188119e-08\n",
       "WESTERN AFRICA     6.032403e-09\n",
       "SOUTH ASIA         3.466338e-09\n",
       "dtype: float64"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank ordered list of geographic regions (in descending order) by high quality articles per capita.\n",
    "\n",
    "# Group by region and sum the high quality articles and population\n",
    "region_hi_article_counts = hi_quality_articles.groupby('region')['article_title'].count()\n",
    "region_population_sums = hi_quality_articles.groupby('region')['population'].sum()\n",
    "\n",
    "# Calculate high quality articles per capita for each region\n",
    "region_hi_articles_per_capita = region_hi_article_counts / (region_population_sums * 10**6)\n",
    "\n",
    "region_hi_articles_per_capita_sorted = region_hi_articles_per_capita.sort_values(ascending=False)\n",
    "region_hi_articles_per_capita_sorted\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data512_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
